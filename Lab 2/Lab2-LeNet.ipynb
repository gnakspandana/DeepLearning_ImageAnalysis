{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f256c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d746d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels(im_name, pat1, pat2):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    im_name : Str\n",
    "    The image file name.\n",
    "    pat1 : Str\n",
    "    A string pattern in the filename for 1st class, e.g \"Mel\"\n",
    "    pat2 : Str\n",
    "    A string pattern in the filename 2nd class, e.g, \"Nev\"\n",
    "    Returns\n",
    "    -------\n",
    "    Label : Numpy array\n",
    "    Class label of the filename name based on its pattern.\n",
    "    '''\n",
    "    if pat1 in im_name:\n",
    "        label = np.array([0])\n",
    "    elif pat2 in im_name:\n",
    "        label = np.array([1])\n",
    "    return label\n",
    "\n",
    "def get_data(data_path, data_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data_path : Str\n",
    "    Path to the data directory\n",
    "    train_list : List\n",
    "    A list containing the name of the images.\n",
    "    img_h : Int\n",
    "    image height to be resized to.\n",
    "    img_w : Int\n",
    "    image width to be resized to.\n",
    "    Returns\n",
    "    -------\n",
    "    img_labels : Nested List\n",
    "    A nested list containing the loaded images along with their\n",
    "    correcponding labels.\n",
    "    \"\"\"\n",
    "    img_labels = []\n",
    "\n",
    "    for item in enumerate(data_list):\n",
    "        img = imread(os.path.join(data_path, item[1]), as_gray = True) # \"as_grey\"\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        img_labels.append([np.array(img), gen_labels(item[1], 'Mel', 'Nev')])\n",
    "\n",
    "        if item[0] % 100 == 0:\n",
    "            print('Reading: {0}/{1} of train images'.format(item[0], len(data_list)))\n",
    "\n",
    "    shuffle(img_labels)\n",
    "\n",
    "    return img_labels\n",
    "\n",
    "def get_data_arrays(nested_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    nested_list : nested list\n",
    "    nested list of image arrays with corresponding class labels.\n",
    "    img_h : Int\n",
    "    Image height.\n",
    "    img_w : Int\n",
    "    Image width.\n",
    "    Returns\n",
    "    -------\n",
    "    img_arrays : Numpy array\n",
    "    4D Array with the size of (n_data,img_h,img_w, 1)\n",
    "    label_arrays : Numpy array\n",
    "    1D array with the size (n_data).\n",
    "    \"\"\"\n",
    "    img_arrays = np.zeros((len(nested_list), img_h, img_w), dtype = np.float32)\n",
    "    label_arrays = np.zeros((len(nested_list)), dtype = np.int32)\n",
    "    for ind in range(len(nested_list)):\n",
    "        img_arrays[ind] = nested_list[ind][0]\n",
    "        label_arrays[ind] = nested_list[ind][1]\n",
    "    img_arrays = np.expand_dims(img_arrays, axis =3)\n",
    "    return img_arrays, label_arrays\n",
    "\n",
    "def get_train_test_arrays(train_data_path, test_data_path, train_list,\n",
    "test_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Get the directory to the train and test sets, the files names and\n",
    "    the size of the image and return the image and label arrays for\n",
    "    train and test sets.\n",
    "    \"\"\"\n",
    "    train_data = get_data(train_data_path, train_list, img_h, img_w)\n",
    "    test_data = get_data(test_data_path, test_list, img_h, img_w)\n",
    "    \n",
    "    train_img, train_label = get_data_arrays(train_data, img_h, img_w)\n",
    "    test_img, test_label = get_data_arrays(test_data, img_h, img_w)\n",
    "    del(train_data)\n",
    "    del(test_data)\n",
    "    return train_img, test_img, train_label, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11959eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 0/1000 of train images\n",
      "Reading: 100/1000 of train images\n",
      "Reading: 200/1000 of train images\n",
      "Reading: 300/1000 of train images\n",
      "Reading: 400/1000 of train images\n",
      "Reading: 500/1000 of train images\n",
      "Reading: 600/1000 of train images\n",
      "Reading: 700/1000 of train images\n",
      "Reading: 800/1000 of train images\n",
      "Reading: 900/1000 of train images\n",
      "Reading: 0/200 of train images\n",
      "Reading: 100/200 of train images\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h = 128, 128 # Setting the width and heights of the images.\n",
    "#data_path = 'Data//DL_course//Lab1//Skin//' # Path to data root with two subdirs.\n",
    "data_path = 'Data/DL_course/Lab1/Skin/' # Path to data root with two subdirs.\n",
    "train_data_path = os.path.join(data_path, 'train')\n",
    "test_data_path = os.path.join(data_path, 'test')\n",
    "\n",
    "train_list = os.listdir(train_data_path)\n",
    "test_list = os.listdir(test_data_path)\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_train_test_arrays(\n",
    "    train_data_path, test_data_path,\n",
    "    train_list, test_list, img_h, img_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5729d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(img_width, img_height, img_ch, base):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Conv2D(base, kernel_size = (3, 3), activation='relu',\n",
    "    strides=1, padding='same',\n",
    "    input_shape = (img_width, img_height, img_ch)))\n",
    "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model1.add(Conv2D(base*2, kernel_size = (3, 3), activation='relu',\n",
    "    strides=1, padding='same'))\n",
    "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(base*2, activation='relu'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model1.summary()\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f0f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4194368   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,213,249\n",
      "Trainable params: 4,213,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6941 - binary_accuracy: 0.4830 - val_loss: 0.6933 - val_binary_accuracy: 0.5050\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6934 - binary_accuracy: 0.5020 - val_loss: 0.6927 - val_binary_accuracy: 0.5400\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6930 - binary_accuracy: 0.5040 - val_loss: 0.6923 - val_binary_accuracy: 0.5400\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6927 - binary_accuracy: 0.5140 - val_loss: 0.6921 - val_binary_accuracy: 0.5350\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6925 - binary_accuracy: 0.5210 - val_loss: 0.6918 - val_binary_accuracy: 0.6150\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6923 - binary_accuracy: 0.5480 - val_loss: 0.6915 - val_binary_accuracy: 0.6100\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6920 - binary_accuracy: 0.5320 - val_loss: 0.6913 - val_binary_accuracy: 0.6150\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6918 - binary_accuracy: 0.5440 - val_loss: 0.6911 - val_binary_accuracy: 0.6200\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6916 - binary_accuracy: 0.5580 - val_loss: 0.6908 - val_binary_accuracy: 0.5800\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6914 - binary_accuracy: 0.5390 - val_loss: 0.6906 - val_binary_accuracy: 0.6150\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6911 - binary_accuracy: 0.5470 - val_loss: 0.6904 - val_binary_accuracy: 0.6200\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6909 - binary_accuracy: 0.5680 - val_loss: 0.6902 - val_binary_accuracy: 0.6300\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6907 - binary_accuracy: 0.5820 - val_loss: 0.6899 - val_binary_accuracy: 0.5950\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6903 - binary_accuracy: 0.5460 - val_loss: 0.6897 - val_binary_accuracy: 0.6200\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6902 - binary_accuracy: 0.5790 - val_loss: 0.6894 - val_binary_accuracy: 0.5900\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6901 - binary_accuracy: 0.5750 - val_loss: 0.6892 - val_binary_accuracy: 0.5950\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6898 - binary_accuracy: 0.5990 - val_loss: 0.6890 - val_binary_accuracy: 0.5650\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6896 - binary_accuracy: 0.5710 - val_loss: 0.6888 - val_binary_accuracy: 0.6100\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.6894 - binary_accuracy: 0.5970 - val_loss: 0.6886 - val_binary_accuracy: 0.6100\n",
      "Epoch 20/200\n",
      " 514/1000 [==============>...............] - ETA: 1s - loss: 0.6898 - binary_accuracy: 0.5195"
     ]
    }
   ],
   "source": [
    "img_ch = x_train[0].shape[2]\n",
    "base=32\n",
    "\n",
    "clf = model(img_w, img_h, img_ch, base)\n",
    "\n",
    "clf.compile(loss='BinaryCrossentropy', optimizer = SGD(learning_rate = 0.00001), metrics=['binary_accuracy']) \n",
    "\n",
    "clf_hist = clf.fit(x_train, y_train, shuffle=True, epochs = 200, batch_size = 1, verbose=1, validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(clf_hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(clf_hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(clf_hist.history[\"val_loss\"]),\n",
    "            np.min(clf_hist.history[\"val_loss\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend();\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(clf_hist.history[\"binary_accuracy\"], label=\"accuracy\")\n",
    "plt.plot(clf_hist.history[\"val_binary_accuracy\"], label=\"val_accuracy\")\n",
    "plt.plot( np.argmax(clf_hist.history[\"val_binary_accuracy\"]),\n",
    "            np.max(clf_hist.history[\"val_binary_accuracy\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
